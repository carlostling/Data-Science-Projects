{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python37464bitbasecondab2efeb2e3ff6431e9e669690c812a191",
      "display_name": "Python 3.7.4 64-bit ('base': conda)"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "@Au\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "bVhbQ0E3mb9S"
      },
      "outputs": [],
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "file spam_2002/0123.68e87f8b736959b1ab5c4b5f2ce7484a was not readable\nfile spam_2002/0273.51c482172b47ce926021aa7cc2552549 was not readable\nfile spam_2002/0330.a4df526233e524104c3b3554dd8ab5a8 was not readable\nfile spam_2002/0334.3e4946e69031f3860ac6de3d3f27aadd was not readable\nfile spam_2002/0335.9822e1787fca0741a8501bdef7e8bc79 was not readable\nfile spam_2002/0123.68e87f8b736959b1ab5c4b5f2ce7484a was not readable\nfile spam_2002/0273.51c482172b47ce926021aa7cc2552549 was not readable\nfile spam_2002/0330.a4df526233e524104c3b3554dd8ab5a8 was not readable\nfile spam_2002/0334.3e4946e69031f3860ac6de3d3f27aadd was not readable\nfile spam_2002/0335.9822e1787fca0741a8501bdef7e8bc79 was not readable\nfile spam_2002/0123.68e87f8b736959b1ab5c4b5f2ce7484a was not readable\nfile spam_2002/0273.51c482172b47ce926021aa7cc2552549 was not readable\nfile spam_2002/0330.a4df526233e524104c3b3554dd8ab5a8 was not readable\nfile spam_2002/0334.3e4946e69031f3860ac6de3d3f27aadd was not readable\nfile spam_2002/0335.9822e1787fca0741a8501bdef7e8bc79 was not readable\n"
        }
      ],
      "source": [
        "\n",
        "def populateDF(dir_label):\n",
        "    emails = pd.DataFrame(columns={\"text\",\"category\",\"category_num\"})\n",
        "    for dir_path in dir_label.keys():\n",
        "        entries = os.listdir(dir_path)\n",
        "        for entry in entries:\n",
        "            entry = dir_path+\"/\"+entry\n",
        "            with open(entry) as file:\n",
        "                try:\n",
        "                    text = file.read()\n",
        "                except:\n",
        "                    print(\"file \"+ entry + \" was not readable\")\n",
        "                    continue\n",
        "                new_row = pd.DataFrame(data={'text': [text], 'category': [dir_label[dir_path]]})\n",
        "                new_row['category_num'] = new_row.category.map({'ham':0, 'spam':1})\n",
        "                emails = emails.append(new_row, ignore_index=True)\n",
        "                  \n",
        "    return emails\n",
        "emails_easy_ham = populateDF({\"easy_ham_2002\":\"ham\",\"spam_2002\":\"spam\"})\n",
        "emails_hard_ham = populateDF({\"hard_ham_2002\":\"ham\",\"spam_2002\":\"spam\"})\n",
        "emails_spam = populateDF({\"spam_2002\":\"spam\"})\n",
        "emails_easy_ham_only = populateDF({\"easy_ham_2002\":\"ham\"})\n",
        "emails_hard_ham_only = populateDF({\"hard_ham_2002\":\"ham\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess(x,y, vectorizer):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1)\n",
        "    x_train = vectorizer.fit_transform(x_train)\n",
        "    x_test = vectorizer.transform(x_test)\n",
        "    y_train = y_train.astype(\"int\")\n",
        "    return x_train, x_test, y_train, y_test\n",
        "\n",
        "x_train_easy, x_test_easy, y_train_easy, y_test_easy = preprocess(emails_easy_ham[\"text\"], emails_easy_ham[\"category_num\"], CountVectorizer())\n",
        "x_train_hard, x_test_hard, y_train_hard, y_test_hard = preprocess(emails_hard_ham[\"text\"], emails_hard_ham[\"category_num\"], CountVectorizer())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "hiMmfkBdgMrw"
      },
      "outputs": [],
      "source": [
        "# Fitting and predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_multiNB(x_train,y_train):\n",
        "    multiNB = MultinomialNB()\n",
        "    multiNB.fit(x_train,y_train)\n",
        "    return multiNB\n",
        "\n",
        "\n",
        "multiNB_easy = train_multiNB(x_train_easy,y_train_easy)\n",
        "multiNB_hard = train_multiNB(x_train_hard,y_train_hard)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_berNB(x_train,y_train):\n",
        "    bernNB = BernoulliNB(binarize=1.0)\n",
        "    bernNB.fit(x_train,y_train)\n",
        "    return bernNB\n",
        "\n",
        "berNB_easy = train_berNB(x_train_easy,y_train_easy)\n",
        "berNB_hard = train_berNB(x_train_hard,y_train_hard)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Accuracy of multiNB on easy ham:  0.9776902887139107\nAccuracy of multiNB on hard ham:  0.9411764705882353\nAccuracy of berNB on easy ham:  0.889763779527559\nAccuracy of berNB on hard ham:  0.8449197860962567\n"
        }
      ],
      "source": [
        "def predict(model, x_test):\n",
        "    y_pred = model.predict(x_test)\n",
        "    return y_pred\n",
        "\n",
        "y_pred_multiNB_easy = predict(multiNB_easy,x_test_easy)\n",
        "y_pred_multiNB_hard = predict(multiNB_hard,x_test_hard)\n",
        "\n",
        "y_pred_berNB_easy = predict(berNB_easy, x_test_easy)\n",
        "y_pred_berNB_hard = predict(berNB_hard, x_test_hard)\n",
        "\n",
        "print(\"Accuracy of multiNB on easy ham: \", accuracy_score(y_pred_multiNB_easy, y_test_easy.to_list()))\n",
        "print(\"Accuracy of multiNB on hard ham: \", accuracy_score(y_pred_multiNB_hard, y_test_hard.to_list()))\n",
        "print(\"Accuracy of berNB on easy ham: \", accuracy_score(y_pred_berNB_easy, y_test_easy.to_list()))\n",
        "print(\"Accuracy of berNB on hard ham: \", accuracy_score(y_pred_berNB_hard, y_test_hard.to_list()))"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# With filtered data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_words(common, words, vectorizer, num):\n",
        "    words = vectorizer.fit_transform(words)\n",
        "    sum_words = words.sum(axis=0)\n",
        "    word_count = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
        "    word_count = pd.DataFrame(word_count)\n",
        "    found_words = word_count.sort_values(by=[1], ascending= not common)[0][0:num]\n",
        "    return found_words\n",
        "common_spam = find_words(True, emails_spam[\"text\"], CountVectorizer(),30).to_list()\n",
        "uncommon_spam = find_words(False, emails_spam[\"text\"], CountVectorizer(),30).to_list()\n",
        "common_easy_ham = find_words(True, emails_easy_ham_only[\"text\"], CountVectorizer(),30).to_list()\n",
        "uncommon_easy_ham = find_words(False, emails_easy_ham_only[\"text\"], CountVectorizer(),30).to_list()\n",
        "common_hard_ham = find_words(True, emails_hard_ham_only[\"text\"], CountVectorizer(),30).to_list()\n",
        "uncommon_hard_ham = find_words(False, emails_hard_ham_only[\"text\"], CountVectorizer(),30).to_list()\n",
        "all_common_and_uncommon = common_spam + uncommon_spam + common_easy_ham + uncommon_easy_ham + common_hard_ham + uncommon_hard_ham"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train_easy_filtered, x_test_easy_filtered, y_train_easy_filtered, y_test_easy_filtered = preprocess(emails_easy_ham[\"text\"], emails_easy_ham[\"category_num\"], CountVectorizer(stop_words=all_common_and_uncommon))\n",
        "\n",
        "x_train_hard_filtered, x_test_hard_filtered, y_train_hard_filtered, y_test_hard_filtered = preprocess(emails_hard_ham[\"text\"], emails_hard_ham[\"category_num\"], CountVectorizer(stop_words=all_common_and_uncommon))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "multiNB_easy_filtered = train_multiNB(x_train_easy_filtered,y_train_easy_filtered)\n",
        "multiNB_hard_filtered = train_multiNB(x_train_hard_filtered,y_train_hard_filtered)\n",
        "\n",
        "berNB_easy_filtered = train_berNB(x_train_easy_filtered,y_train_easy_filtered)\n",
        "berNB_hard_filtered = train_berNB(x_train_hard_filtered,y_train_hard_filtered)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Accuracy of multiNB on filtered easy ham:  0.994750656167979\nAccuracy of multiNB on filtered hard ham:  0.9946524064171123\nAccuracy of berNB on filtered easy ham:  0.8753280839895013\nAccuracy of berNB on filtered hard ham:  0.8342245989304813\n"
        }
      ],
      "source": [
        "y_pred_multiNB_easy_filtered = predict(multiNB_easy_filtered,x_test_easy_filtered)\n",
        "y_pred_multiNB_hard_filtered = predict(multiNB_hard_filtered,x_test_hard_filtered)\n",
        "\n",
        "y_pred_berNB_easy_filtered = predict(berNB_easy_filtered, x_test_easy_filtered)\n",
        "y_pred_berNB_hard_filtered = predict(berNB_hard_filtered, x_test_hard_filtered)\n",
        "\n",
        "print(\"Accuracy of multiNB on filtered easy ham: \", accuracy_score(y_pred_multiNB_easy_filtered, y_test_easy_filtered.to_list()))\n",
        "print(\"Accuracy of multiNB on filtered hard ham: \", accuracy_score(y_pred_multiNB_hard_filtered, y_test_hard_filtered.to_list()))\n",
        "print(\"Accuracy of berNB on filtered easy ham: \", accuracy_score(y_pred_berNB_easy_filtered, y_test_easy_filtered.to_list()))\n",
        "print(\"Accuracy of berNB on filtered hard ham: \", accuracy_score(y_pred_berNB_hard_filtered, y_test_hard_filtered.to_list()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}